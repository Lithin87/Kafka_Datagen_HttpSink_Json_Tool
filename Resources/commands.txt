confluent connect cluster create --config-file datagen-source-config.json

confluent connect cluster list

confluent connect plugin describe DatagenSource -o json

confluent kafka topic delete transactions

confluent connect delete <connector ID>

confluent connect describe <connector ID>

confluent connect resume <connector ID>

confluent connect pause <connector ID>

=================================================================================
sleep 60
docker exec -it connect bash   
apt install -y default-jdk     done
curl "https://client.hub.confluent.io/confluent-hub-client-latest.tar.gz" -o hub
tar -xzvf hub
cd bin
y | confluent-hub install confluentinc/kafka-connect-http:1.7.2
exit
docker restart connect

  chmod +x /usr/local/bin/docker-compose
  cd bin && ./confluent-hub
  #chmod +x confluent-hub
 


/etc/kafka/connect-distributed.properties
./confluent-hub install confluentinc/kafka-connect-http:latest --component-dir <path-to-component-directory> --worker-configs <path-to-worker-configs-file>
usr/share/confluent-hub-components
etc/kafka-connect/kafka-connect.properties
lithin87/ust_sink_connector

{
  "connect.name": "lithin.personal.ust_data",
  "fields": [
    {
      "name": "store_id",
      "type": "int"
    },
    {
      "name": "order_lines",
      "type": {
        "items": {
          "connect.name": "lithin.personal.order_line",
          "fields": [
            {
              "name": "product_id",
              "type": "int"
            },
            {
              "name": "category",
              "type": "string"
            },
            {
              "name": "quantity",
              "type": "int"
            },
            {
              "name": "unit_price",
              "type": "float"
            },
            {
              "name": "net_price",
              "type": "float"
            }
          ],
          "name": "order_line",
          "type": "record"
        },
        "type": "array"
      }
    }
  ],
  "name": "ust_data",
  "namespace": "lithin.personal",
  "type": "record"
}



  console.log("Hello : "+req.body);

value.converter=org.apache.kafka.connect.json.JsonConverter
              

{
  "name": "HttpSinkConnectorConnector_0",
  "config": {
    "value.converter.schema.registry.url": "http://schema-registry:8081",
    "name": "HttpSinkConnectorConnector_0",
    "connector.class": "io.confluent.connect.http.HttpSinkConnector",
    "key.converter": "org.apache.kafka.connect.storage.StringConverter",
    "value.converter": "io.confluent.connect.avro.AvroConverter",
    "topics": "Regex_Schema",
    "http.api.url": "https://kafkasinkcollector-tava5544oa-uc.a.run.app",
    "request.method": "post",
    "reporter.result.topic.replication.factor": "1",
    "reporter.error.topic.replication.factor": "1",
    "reporter.bootstrap.servers": "broker:29092"
  }
}

const machineImage = 'projects/ecstatic-cosmos-387220/global/machineImages/kafka-datagen-connect-image'; // Replace with your machine image URL

   instanceResource: {
      name: instanceName,
      sourceMachineImage: machineImage,
      metadata: {
        items: [
          {
            key: 'startup-script',
            value: `
              #!/bin/bash
              git clone https://github.com/Lithin87/Kafka_Datagen_HttpSink_Json_Tool.git /home/ravindcable4/app
              cd /home/ravindcable4/app/Resources && docker-compose start `,
          },
        ],
      },
    },